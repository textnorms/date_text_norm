{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5: V12 En-relative-dates.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c9881f6b5b6436c9210b640d3909845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f3c68ad51fc42bea3591ac0f66062dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74a42e51ce9945af8c610917689dada4",
              "IPY_MODEL_c76fbaa98f824d5494686f9843aca732"
            ]
          }
        },
        "1f3c68ad51fc42bea3591ac0f66062dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74a42e51ce9945af8c610917689dada4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b2f54f0c950496a952659594eebebbc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec51ea3bb14e43faa5fcb5e48c40e21e"
          }
        },
        "c76fbaa98f824d5494686f9843aca732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b19af17a52aa4885be6b74d394e3d1ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:00&lt;00:00, 964kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52013fb621774911aaeeb3582472579b"
          }
        },
        "2b2f54f0c950496a952659594eebebbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec51ea3bb14e43faa5fcb5e48c40e21e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b19af17a52aa4885be6b74d394e3d1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52013fb621774911aaeeb3582472579b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/textnorms/date_text_norm/blob/master/T5_V12_En_relative_dates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcMfqlK-0HLY",
        "colab_type": "code",
        "outputId": "73212d45-a15e-4847-ebc1-ab5b97059736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 14 17:14:16 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-1Lmkfv6g2j",
        "colab_type": "code",
        "outputId": "91b1a085-7c5b-48b2-d036-bb305efcbf2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "! rm -rf date*\n",
        "! git clone https://github.com/textnorms/date_text_norm.git\n",
        "! cp -r date_text_norm/syntetic_data/ .\n",
        "\n",
        "! pip install -q num2words transformers\n",
        "! pip install -q transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'date_text_norm'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 294 (delta 48), reused 57 (delta 26), pack-reused 211\u001b[K\n",
            "Receiving objects: 100% (294/294), 1.44 MiB | 3.33 MiB/s, done.\n",
            "Resolving deltas: 100% (166/166), done.\n",
            "\u001b[K     |████████████████████████████████| 102kB 5.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 675kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 23.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 57.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAYiZO6Teo-y",
        "colab_type": "text"
      },
      "source": [
        "# Libs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmrMJ5fSgr3P",
        "colab_type": "text"
      },
      "source": [
        "### Choose Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbOvMx-Igq7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LANGUAGE = 'pt'\n",
        "LANGUAGE = 'en'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nok2mtt_1021",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Synthetic data generator\n",
        "from syntetic_data import DateTextGenerator\n",
        "from syntetic_data import RelativeDateTextGenerator\n",
        "\n",
        "# PyTorch\n",
        "import torch \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
        "\n",
        "# Matplot lib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhdTvVgiYBw0",
        "colab_type": "text"
      },
      "source": [
        "### Deterministic experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm7tAsiUYMOU",
        "colab_type": "code",
        "outputId": "3d57f7b9-d25b-4480-b4c8-983bb792966f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "manual_seed = 2357 # only primes, cuz I like\n",
        "def deterministic(rep=True):\n",
        "    if rep:\n",
        "        np.random.seed(manual_seed)\n",
        "        torch.manual_seed(manual_seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(manual_seed)\n",
        "            torch.cuda.manual_seed_all(manual_seed)\n",
        "        torch.backends.cudnn.enabled = False \n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f'Deterministic experiment, seed: {manual_seed}')\n",
        "    else:\n",
        "        print('Random experiment')\n",
        "\n",
        "deterministic()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 2357\n",
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFHYoyzwOHDO",
        "colab_type": "text"
      },
      "source": [
        "# Config constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r8O913HOK9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "9c9881f6b5b6436c9210b640d3909845",
            "1f3c68ad51fc42bea3591ac0f66062dd",
            "74a42e51ce9945af8c610917689dada4",
            "c76fbaa98f824d5494686f9843aca732",
            "2b2f54f0c950496a952659594eebebbc",
            "ec51ea3bb14e43faa5fcb5e48c40e21e",
            "b19af17a52aa4885be6b74d394e3d1ac",
            "52013fb621774911aaeeb3582472579b"
          ]
        },
        "outputId": "d2dcb5e2-e009-4179-d995-b81f3f83a06b"
      },
      "source": [
        "# Model params\n",
        "MODEL_SZ = 't5-small' # 't5-base'\n",
        "TOK = T5Tokenizer.from_pretrained(MODEL_SZ)\n",
        "MAX_LEN_SRC  = 48\n",
        "MAX_LEN_TRGT = 12\n",
        "\n",
        "# Train params\n",
        "BATCH_SZ = 16\n",
        "N_EPOCHS = 50\n",
        "WINDOW   = 7"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c9881f6b5b6436c9210b640d3909845",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yeoFiMYXe8Z",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ52EJP6Fy5v",
        "colab_type": "code",
        "outputId": "9a1d3479-eb19-4729-cec5-1a570dc48e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pd.set_option('display.max_rows',70)\n",
        "\n",
        "print('Generating absolute and incomplete dates')\n",
        "dates = DateTextGenerator(start_date='01/01/1921',\n",
        "                          end_date='31/12/2120',\n",
        "                          text_noise_rate=0.0,\n",
        "                          language=LANGUAGE)\n",
        "\n",
        "print('Generating relative dates')\n",
        "rel_dates = RelativeDateTextGenerator(text_noise_rate=0.0,\n",
        "                                       max_noise_occurences_per_sample=3,\n",
        "                                       samples_per_method=15,\n",
        "                                       language=LANGUAGE)\n",
        "\n",
        "df = dates.generate_date_dataset()\n",
        "df = df.append(rel_dates.generate_date_dataset(),ignore_index=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating absolute and incomplete dates\n",
            "Generating relative dates\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdMrRLTELs-L",
        "colab_type": "code",
        "outputId": "c15786dc-8094-4754-ba5d-c3045461a061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Pattern</th>\n",
              "      <th>Noise Type</th>\n",
              "      <th>Input</th>\n",
              "      <th>Target</th>\n",
              "      <th>Target Format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>N/A</td>\n",
              "      <td>01 january one thousand, nine hundred and twen...</td>\n",
              "      <td>01/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>N/A</td>\n",
              "      <td>02 - 1 - 1921</td>\n",
              "      <td>02/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>N/A</td>\n",
              "      <td>03 - jan - 1921</td>\n",
              "      <td>03/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>N/A</td>\n",
              "      <td>04 . 1 . 1921</td>\n",
              "      <td>04/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>N/A</td>\n",
              "      <td>five - 01 - 1921</td>\n",
              "      <td>05/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Input Pattern Noise Type  ...      Target Target Format\n",
              "0             16        N/A  ...  01/01/1921    DD/MM/YYYY\n",
              "1             23        N/A  ...  02/01/1921    DD/MM/YYYY\n",
              "2             29        N/A  ...  03/01/1921    DD/MM/YYYY\n",
              "3             31        N/A  ...  04/01/1921    DD/MM/YYYY\n",
              "4              8        N/A  ...  05/01/1921    DD/MM/YYYY\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wojl91rJNEmC",
        "colab_type": "code",
        "outputId": "1bd55c25-a404-493f-8a88-97110b3ae922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df['Target Format'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DD/MM/YYYY    73049\n",
              "MM/YYYY        7200\n",
              "DD/MM          2562\n",
              "Relative       1500\n",
              "Name: Target Format, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UquMxgpcNO3t",
        "colab_type": "code",
        "outputId": "8c0990ca-300d-47f0-d0a4-3482fa97d909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df.loc[df['Target Format'] == 'MM/YYYY']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Pattern</th>\n",
              "      <th>Noise Type</th>\n",
              "      <th>Input</th>\n",
              "      <th>Target</th>\n",
              "      <th>Target Format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75611</th>\n",
              "      <td>2</td>\n",
              "      <td>N/A</td>\n",
              "      <td>jan of one thousand, nine hundred and twenty-one</td>\n",
              "      <td>01/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75612</th>\n",
              "      <td>30</td>\n",
              "      <td>N/A</td>\n",
              "      <td>1.1921</td>\n",
              "      <td>01/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75613</th>\n",
              "      <td>36</td>\n",
              "      <td>N/A</td>\n",
              "      <td>jan.1921</td>\n",
              "      <td>01/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75614</th>\n",
              "      <td>17</td>\n",
              "      <td>N/A</td>\n",
              "      <td>02 one thousand, nine hundred and twenty-one</td>\n",
              "      <td>02/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75615</th>\n",
              "      <td>40</td>\n",
              "      <td>N/A</td>\n",
              "      <td>february/1921</td>\n",
              "      <td>02/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82806</th>\n",
              "      <td>7</td>\n",
              "      <td>N/A</td>\n",
              "      <td>11 of two thousand, one hundred and twenty</td>\n",
              "      <td>11/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82807</th>\n",
              "      <td>10</td>\n",
              "      <td>N/A</td>\n",
              "      <td>november of 2120</td>\n",
              "      <td>11/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82808</th>\n",
              "      <td>8</td>\n",
              "      <td>N/A</td>\n",
              "      <td>12 - 2120</td>\n",
              "      <td>12/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82809</th>\n",
              "      <td>17</td>\n",
              "      <td>N/A</td>\n",
              "      <td>12 two thousand, one hundred and twenty</td>\n",
              "      <td>12/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82810</th>\n",
              "      <td>13</td>\n",
              "      <td>N/A</td>\n",
              "      <td>December/2120</td>\n",
              "      <td>12/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7200 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Input Pattern Noise Type  ...   Target Target Format\n",
              "75611              2        N/A  ...  01/1921       MM/YYYY\n",
              "75612             30        N/A  ...  01/1921       MM/YYYY\n",
              "75613             36        N/A  ...  01/1921       MM/YYYY\n",
              "75614             17        N/A  ...  02/1921       MM/YYYY\n",
              "75615             40        N/A  ...  02/1921       MM/YYYY\n",
              "...              ...        ...  ...      ...           ...\n",
              "82806              7        N/A  ...  11/2120       MM/YYYY\n",
              "82807             10        N/A  ...  11/2120       MM/YYYY\n",
              "82808              8        N/A  ...  12/2120       MM/YYYY\n",
              "82809             17        N/A  ...  12/2120       MM/YYYY\n",
              "82810             13        N/A  ...  12/2120       MM/YYYY\n",
              "\n",
              "[7200 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fBsISzKzIXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "73561740-dd52-49e9-ee24-fbfdcf9ced0c"
      },
      "source": [
        "df.loc[df['Target Format'] == 'Relative']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Pattern</th>\n",
              "      <th>Noise Type</th>\n",
              "      <th>Input</th>\n",
              "      <th>Target</th>\n",
              "      <th>Target Format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82811</th>\n",
              "      <td>17</td>\n",
              "      <td>N/A</td>\n",
              "      <td>during 1 year</td>\n",
              "      <td>1y</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82812</th>\n",
              "      <td>2</td>\n",
              "      <td>N/A</td>\n",
              "      <td>one day ago</td>\n",
              "      <td>-1d</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82813</th>\n",
              "      <td>6</td>\n",
              "      <td>N/A</td>\n",
              "      <td>one year ago</td>\n",
              "      <td>-1y</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82814</th>\n",
              "      <td>3</td>\n",
              "      <td>N/A</td>\n",
              "      <td>1 month ago</td>\n",
              "      <td>-1m</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82815</th>\n",
              "      <td>9</td>\n",
              "      <td>N/A</td>\n",
              "      <td>for 1 month</td>\n",
              "      <td>1m</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84306</th>\n",
              "      <td>1</td>\n",
              "      <td>N/A</td>\n",
              "      <td>100 days ago</td>\n",
              "      <td>-100d</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84307</th>\n",
              "      <td>9</td>\n",
              "      <td>N/A</td>\n",
              "      <td>for 100 months</td>\n",
              "      <td>100m</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84308</th>\n",
              "      <td>4</td>\n",
              "      <td>N/A</td>\n",
              "      <td>one hundred months ago</td>\n",
              "      <td>-100m</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84309</th>\n",
              "      <td>5</td>\n",
              "      <td>N/A</td>\n",
              "      <td>100 years ago</td>\n",
              "      <td>-100y</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84310</th>\n",
              "      <td>13</td>\n",
              "      <td>N/A</td>\n",
              "      <td>during 100 days</td>\n",
              "      <td>100d</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Input Pattern Noise Type                   Input Target Target Format\n",
              "82811             17        N/A           during 1 year     1y      Relative\n",
              "82812              2        N/A             one day ago    -1d      Relative\n",
              "82813              6        N/A            one year ago    -1y      Relative\n",
              "82814              3        N/A             1 month ago    -1m      Relative\n",
              "82815              9        N/A             for 1 month     1m      Relative\n",
              "...              ...        ...                     ...    ...           ...\n",
              "84306              1        N/A            100 days ago  -100d      Relative\n",
              "84307              9        N/A          for 100 months   100m      Relative\n",
              "84308              4        N/A  one hundred months ago  -100m      Relative\n",
              "84309              5        N/A           100 years ago  -100y      Relative\n",
              "84310             13        N/A         during 100 days   100d      Relative\n",
              "\n",
              "[1500 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5sp50kPNZhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing dates in the defined Target Format\n",
        "df = df.loc[df['Target Format'] == 'Relative']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t6fSj8fyyya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1610aa1f-9525-4891-df51-8650d98ec667"
      },
      "source": [
        "# Inspecting the relative dates dataset\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Pattern</th>\n",
              "      <th>Noise Type</th>\n",
              "      <th>Input</th>\n",
              "      <th>Target</th>\n",
              "      <th>Target Format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82811</th>\n",
              "      <td>17</td>\n",
              "      <td>N/A</td>\n",
              "      <td>during 1 year</td>\n",
              "      <td>1y</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82812</th>\n",
              "      <td>2</td>\n",
              "      <td>N/A</td>\n",
              "      <td>one day ago</td>\n",
              "      <td>-1d</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82813</th>\n",
              "      <td>6</td>\n",
              "      <td>N/A</td>\n",
              "      <td>one year ago</td>\n",
              "      <td>-1y</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82814</th>\n",
              "      <td>3</td>\n",
              "      <td>N/A</td>\n",
              "      <td>1 month ago</td>\n",
              "      <td>-1m</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82815</th>\n",
              "      <td>9</td>\n",
              "      <td>N/A</td>\n",
              "      <td>for 1 month</td>\n",
              "      <td>1m</td>\n",
              "      <td>Relative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Input Pattern Noise Type          Input Target Target Format\n",
              "82811             17        N/A  during 1 year     1y      Relative\n",
              "82812              2        N/A    one day ago    -1d      Relative\n",
              "82813              6        N/A   one year ago    -1y      Relative\n",
              "82814              3        N/A    1 month ago    -1m      Relative\n",
              "82815              9        N/A    for 1 month     1m      Relative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uif9PsFKRrxI",
        "colab_type": "text"
      },
      "source": [
        "## Function to split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfBx9nMkQ7Q8",
        "colab_type": "code",
        "outputId": "95b40c4e-98ee-47c7-adf5-b459852da78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def split_data(df, test_size=0.2, verbose=True):\n",
        "    l = list(set(df['Input Pattern'].values))\n",
        "    num_test = int(len(l)*test_size)\n",
        "    test_methods = [random.randint(1, len(l)) for _ in range(num_test)]\n",
        "    print(test_methods)\n",
        "    df_test = df[df['Input Pattern'].isin(test_methods)]\n",
        "    print(df_test.shape)\n",
        "    x_test = df_test.Input.values\n",
        "    y_test = df_test.Target.values\n",
        "\n",
        "    df_train = df[~df['Input Pattern'].isin(test_methods)]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        df_train.Input.values,\n",
        "        df_train.Target.values,\n",
        "        shuffle=True, \n",
        "        test_size=test_size,\n",
        "        random_state=manual_seed\n",
        "        )\n",
        "    if verbose:\n",
        "        print(f'Date types of test set: {test_methods} with len: {len(test_methods)}')\n",
        "        print(f'x_train: {len(x_train)}  --  y_train: {len(y_train)}\\n\\\n",
        "x_val:   {len(x_val)}  --  y_val:   {len(y_val)}\\n\\\n",
        "x_test:  {len(x_test)}  --  y_test:  {len(y_test)}')\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "# creating sets\n",
        "x_train, y_train, x_val, y_val, x_test, y_test = split_data(df, \n",
        "                                                            test_size=0.25, \n",
        "                                                            verbose=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 15, 2, 11]\n",
            "(339, 5)\n",
            "Date types of test set: [3, 15, 2, 11] with len: 4\n",
            "x_train: 870  --  y_train: 870\n",
            "x_val:   291  --  y_val:   291\n",
            "x_test:  339  --  y_test:  339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygsMXnkCyrVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DateDataset(Dataset):\n",
        "    def __init__(self, data, label, tokenizer, source_max_length, target_max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "        self.source_max_length = source_max_length\n",
        "        self.target_max_length = target_max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        source = self.data[idx]\n",
        "        target = self.label[idx]\n",
        "\n",
        "        source_tokenized = self.tokenizer.encode_plus(\n",
        "            f'{source} {self.tokenizer.eos_token}',\n",
        "            max_length=self.source_max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt')\n",
        "\n",
        "        target_tokenized = self.tokenizer.encode_plus(\n",
        "            f'{target} {self.tokenizer.eos_token}',\n",
        "            max_length=self.target_max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt')\n",
        "\n",
        "        source_token_ids = source_tokenized['input_ids'].squeeze()\n",
        "        source_mask = source_tokenized['attention_mask'].squeeze()\n",
        "        target_token_ids = target_tokenized['input_ids'].squeeze()\n",
        "        \n",
        "        return source_token_ids, source_mask, target_token_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloyt0tIwIiD",
        "colab_type": "text"
      },
      "source": [
        "## Checking the DateDataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoKiQXCvwGrP",
        "colab_type": "code",
        "outputId": "77ad4384-93f0-4963-ed7e-d842097bc5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "dataset_debug = DateDataset(\n",
        "    x_train, \n",
        "    y_train,\n",
        "    TOK,\n",
        "    MAX_LEN_SRC,\n",
        "    MAX_LEN_TRGT,\n",
        "    )\n",
        "\n",
        "dataloader_checking = DataLoader(\n",
        "    dataset_debug, \n",
        "    batch_size=1, \n",
        "    shuffle=True, \n",
        "    num_workers=0\n",
        "    )\n",
        "\n",
        "source_token_ids, source_mask, target_token_ids = next(iter(dataloader_checking))\n",
        "print(f'source_token_ids:\\n {source_token_ids} --- shape:{source_token_ids.shape}')\n",
        "print(f'source_mask:\\n {source_mask} --- shape:{source_mask.shape}')\n",
        "print(f'target_token_ids:\\n {target_token_ids} --- shape:{target_token_ids.shape}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source_token_ids:\n",
            " tensor([[ 383, 4169,  477,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]) --- shape:torch.Size([1, 48])\n",
            "source_mask:\n",
            " tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) --- shape:torch.Size([1, 48])\n",
            "target_token_ids:\n",
            " tensor([[668,  26,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0]]) --- shape:torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG1O12UoWYaM",
        "colab_type": "text"
      },
      "source": [
        "## Datasets e Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7AlRyeOW8GN",
        "colab_type": "code",
        "outputId": "452d2933-c578-4617-9c09-54c1086bc018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# datasets\n",
        "ds_debug = DateDataset(x_train[:BATCH_SZ], y_train[:BATCH_SZ], TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "ds_train = DateDataset(x_train, y_train, TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "ds_valid = DateDataset(x_val, y_val, TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "ds_test  = DateDataset(x_test, y_test, TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "\n",
        "print('Datasets len:')\n",
        "print(f'len ds_debug: {len(ds_debug)}')\n",
        "print(f'len ds_train: {len(ds_train)}')\n",
        "print(f'len ds_valid: {len(ds_valid)}')\n",
        "print(f'len ds_test:  {len(ds_test)}')\n",
        "\n",
        "# dataloaders\n",
        "dataloaders = {\n",
        "    'debug': DataLoader(\n",
        "         ds_debug,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=True,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "    'train': DataLoader(\n",
        "         ds_train,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=True,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "    'valid': DataLoader(\n",
        "         ds_valid,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=False,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "    'test': DataLoader(\n",
        "         ds_test,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=False,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "               }\n",
        "# sanity check\n",
        "print('\\nDataloaders len (in batch):')\n",
        "dl_sizes = {x: len(dataloaders[x]) for x in dataloaders.keys()}; dl_sizes"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets len:\n",
            "len ds_debug: 16\n",
            "len ds_train: 870\n",
            "len ds_valid: 291\n",
            "len ds_test:  339\n",
            "\n",
            "Dataloaders len (in batch):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debug': 1, 'test': 22, 'train': 55, 'valid': 19}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3rqg6r7am-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testando o dataloader \n",
        "source_token_ids, source_mask, target_token_ids = next(iter(dataloaders['debug']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb4AnOJzBXK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_SZ)\n",
        "    \n",
        "    def forward(self, token_ids, att_mask, labels):\n",
        "        outputs = self.model.forward(\n",
        "            input_ids=token_ids, \n",
        "            attention_mask=att_mask,\n",
        "            lm_labels=labels\n",
        "            )\n",
        "        return outputs[0] # loss\n",
        "    \n",
        "    @torch.no_grad()    \n",
        "    def generate(self, token_ids, att_mask, max_len_target):\n",
        "        predict = self.model.generate(\n",
        "            input_ids=token_ids, \n",
        "            attention_mask=att_mask,\n",
        "            max_length=max_len_target\n",
        "            )\n",
        "        return predict\n",
        "    \n",
        "    @torch.no_grad()  \n",
        "    def generate_example(self, text_input, tokenizer, max_len_source=MAX_LEN_SRC):\n",
        "\n",
        "        self.model.eval()\n",
        "        \n",
        "        example_tokenized = tokenizer.encode_plus(\n",
        "            f'{text_input} {tokenizer.eos_token}',\n",
        "            max_length=max_len_source,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt')\n",
        "            \n",
        "        example_token_ids = example_tokenized['input_ids']\n",
        "        example_mask = example_tokenized['attention_mask']\n",
        "\n",
        "        predicted_example = self.model.generate(\n",
        "            input_ids=example_token_ids.to(device), \n",
        "            attention_mask=example_mask.to(device),\n",
        "            max_length=MAX_LEN_TRGT\n",
        "            )\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        out_text = [tokenizer.decode(text) for text in predicted_example]\n",
        "        \n",
        "        return out_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq9AMCaNuWMU",
        "colab_type": "text"
      },
      "source": [
        "## Train and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X6hklAUXxGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# acc metric for text inputs\n",
        "def acc_in_text(trues, preds): \n",
        "    acc = []\n",
        "    for d in zip(trues, preds):\n",
        "        if d[0] == d[1]:\n",
        "            acc.append(1)\n",
        "        else:\n",
        "            acc.append(0)\n",
        "    return acc # bool\n",
        "\n",
        "def train(model, device, train_loader, optimizer):\n",
        "    loss_train = []\n",
        "    model.train()\n",
        "    for source_token_ids, source_mask, target_token_ids in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(\n",
        "            source_token_ids.to(device), \n",
        "            source_mask.to(device), \n",
        "            target_token_ids.to(device)\n",
        "            )\n",
        "        \n",
        "        loss_train.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    train_losses = sum(loss_train) / len(loss_train)\n",
        "  \n",
        "    return train_losses\n",
        "\n",
        "def evaluate_fn(model, device, val_loader, max_len=MAX_LEN_TRGT):\n",
        "    loss_val, all_acc, all_preds, all_trues = [], [], [], []\n",
        "    model.eval()\n",
        "    for source_token_ids, source_mask, target_token_ids in val_loader:\n",
        "        predicted_ids = model.generate(\n",
        "            source_token_ids.to(device), \n",
        "            source_mask.to(device),\n",
        "            max_len\n",
        "            )\n",
        "        \n",
        "        preds = [TOK.decode(t) for t in predicted_ids]\n",
        "        trues = [TOK.decode(t) for t in target_token_ids]\n",
        "        acc = acc_in_text(trues, preds)\n",
        "        all_acc.extend(acc)\n",
        "        all_trues.extend(trues)\n",
        "        all_preds.extend(preds)\n",
        "        \n",
        "        # val loss   \n",
        "        loss = model(\n",
        "        source_token_ids.to(device), \n",
        "        source_mask.to(device), \n",
        "        target_token_ids.to(device)\n",
        "        )\n",
        "        loss_val.append(loss.item())\n",
        "    \n",
        "    val_losses = sum(loss_val) / len(loss_val)\n",
        "    \n",
        "    return val_losses, np.array(all_acc).mean(), all_trues, all_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pirS1mecELqp",
        "colab_type": "text"
      },
      "source": [
        "# Overfit in one batch \n",
        "- dataloader debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PxRYyfn_UO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d9c06e59-02ae-475c-ac98-eb88ba252989"
      },
      "source": [
        "overfit = True\n",
        "\n",
        "if overfit:\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    deterministic() \n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "    \n",
        "    # -----------------------------------------------------------------------------\n",
        "    start.record()\n",
        "    for step in range(1, 1001):\n",
        "        samp = random.randint(0, BATCH_SZ-WINDOW) # to show random trues and preds\n",
        "        loss_t = train(model, device, dataloaders['debug'], optimizer)\n",
        "        loss,acc, trues, preds = evaluate_fn(model, device, dataloaders['debug'])\n",
        "        if step == 1:\n",
        "            print(f'[Epoch: {step}/{1000}] |', end=' ')\n",
        "            print(f'Train Loss: {loss_t:.3f} -- Acc: {acc:.3f}')\n",
        "        if step % 100 == 0:\n",
        "            print(f'[Epoch: {step}/{1000}] |', end=' ')\n",
        "            print(f'Train Loss: {loss_t:.3f} -- Acc: {acc:.3f}')\n",
        "            print(f'  Trues: {trues[samp:samp+WINDOW]}\\n  Preds: {preds[samp:samp+WINDOW]}')\n",
        "        if acc>= 0.99:\n",
        "          print('The model has overfitted! Breaking the loop :)')\n",
        "          break\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()    \n",
        "    # -----------------------------------------------------------------------------\n",
        "\n",
        "    print(f'Training time: {start.elapsed_time(end)/1000/60 :.3f} min.')\n",
        "    del model"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 2357\n",
            "[Epoch: 1/1000] | Train Loss: 13.511 -- Acc: 0.000\n",
            "[Epoch: 100/1000] | Train Loss: 1.240 -- Acc: 0.000\n",
            "  Trues: ['51d', '20y', '34d', '-65m', '38d', '-6m', '67m']\n",
            "  Preds: ['', '', '', '', '', '', '']\n",
            "[Epoch: 200/1000] | Train Loss: 0.196 -- Acc: 0.875\n",
            "  Trues: ['71y', '76y', '20y', '5m', '-19y', '13d', '34d']\n",
            "  Preds: ['71y', '76y', '20y', '5m', '190y', '13d', '34d']\n",
            "The model has overfitted! Breking the loop :)\n",
            "Training time: 1.752 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQC8YJ8PT7-0",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNtIb8b4Q4lC",
        "colab_type": "code",
        "outputId": "839ddc4e-e826-49b7-d2b1-e4ffaa765792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "try:\n",
        "  del model\n",
        "except:\n",
        "  print('Model already erased, starting a new one!')\n",
        "  \n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "deterministic() \n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "start.record()\n",
        "for step in range(1, N_EPOCHS+1):\n",
        "    samp = random.randint(0, BATCH_SZ-WINDOW) # to show random trues and preds\n",
        "    loss_t = train(model, device, dataloaders['train'], optimizer)\n",
        "    loss_v, acc, trues, preds = evaluate_fn(model, device, dataloaders['valid'])\n",
        "    print(f'[Epoch: {step}/{N_EPOCHS}] |', end=' ')\n",
        "    print(f'Train Loss: {loss_t:.3f} -- Valid Loss: {loss_v:.3f} -- Acc: {acc:.3f}')\n",
        "    print(f'  Trues: {trues[samp:samp+WINDOW]}\\n  Preds: {preds[samp:samp+WINDOW]}')\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()    \n",
        "# ---------------------------------------------------------------------------------\n",
        "\n",
        "print(f'Training time: {start.elapsed_time(end)/1000/60 :.3f} min.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model already erased, starting a new one!\n",
            "Deterministic experiment, seed: 2357\n",
            "[Epoch: 1/50] | Train Loss: 4.631 -- Valid Loss: 1.452 -- Acc: 0.000\n",
            "  Trues: ['-74m', '-53y', '92d', '-17y', '10m', '55d', '42y']\n",
            "  Preds: ['', '', '', '', '', '', '']\n",
            "[Epoch: 2/50] | Train Loss: 1.774 -- Valid Loss: 0.575 -- Acc: 0.024\n",
            "  Trues: ['-17y', '10m', '55d', '42y', '31m', '55m', '4d']\n",
            "  Preds: ['', '', '', '', '', '', '']\n",
            "[Epoch: 3/50] | Train Loss: 0.797 -- Valid Loss: 0.186 -- Acc: 0.553\n",
            "  Trues: ['-74m', '-53y', '92d', '-17y', '10m', '55d', '42y']\n",
            "  Preds: ['74m', '53y', '92d', '17y', 'zehnm', '55d', '42y']\n",
            "[Epoch: 4/50] | Train Loss: 0.347 -- Valid Loss: 0.109 -- Acc: 0.639\n",
            "  Trues: ['84y', '-48m', '-74m', '-53y', '92d', '-17y', '10m']\n",
            "  Preds: ['84y', '-48m', '74m', '53y', '92d', '17y', 'zehnm']\n",
            "[Epoch: 5/50] | Train Loss: 0.236 -- Valid Loss: 0.074 -- Acc: 0.722\n",
            "  Trues: ['42y', '31m', '55m', '4d', '3m', '59d', '-31m']\n",
            "  Preds: ['42y', '31m', '55m', '4d', '3m', '59d', '-31m']\n",
            "[Epoch: 6/50] | Train Loss: 0.180 -- Valid Loss: 0.052 -- Acc: 0.869\n",
            "  Trues: ['-17y', '10m', '55d', '42y', '31m', '55m', '4d']\n",
            "  Preds: ['-17y', 'zehnm', '55d', '42y', '31m', '55m', '4d']\n",
            "[Epoch: 7/50] | Train Loss: 0.139 -- Valid Loss: 0.040 -- Acc: 0.893\n",
            "  Trues: ['55d', '42y', '31m', '55m', '4d', '3m', '59d']\n",
            "  Preds: ['55d', '42y', '31m', '55m', '4d', '3m', '59d']\n",
            "[Epoch: 8/50] | Train Loss: 0.110 -- Valid Loss: 0.032 -- Acc: 0.918\n",
            "  Trues: ['55d', '42y', '31m', '55m', '4d', '3m', '59d']\n",
            "  Preds: ['55d', '42y', '31m', '55m', '4d', '3m', '59d']\n",
            "[Epoch: 9/50] | Train Loss: 0.096 -- Valid Loss: 0.027 -- Acc: 0.918\n",
            "  Trues: ['10m', '55d', '42y', '31m', '55m', '4d', '3m']\n",
            "  Preds: ['zehnm', '55d', '42y', '31m', '55m', '4d', '3m']\n",
            "[Epoch: 10/50] | Train Loss: 0.078 -- Valid Loss: 0.023 -- Acc: 0.942\n",
            "  Trues: ['84y', '-48m', '-74m', '-53y', '92d', '-17y', '10m']\n",
            "  Preds: ['84y', '-48m', '-74m', '-53y', '92d', '-17y', 'zehnm']\n",
            "[Epoch: 11/50] | Train Loss: 0.068 -- Valid Loss: 0.020 -- Acc: 0.942\n",
            "  Trues: ['-48m', '-74m', '-53y', '92d', '-17y', '10m', '55d']\n",
            "  Preds: ['-48m', '-74m', '-53y', '92d', '-17y', 'zehnm', '55d']\n",
            "[Epoch: 12/50] | Train Loss: 0.060 -- Valid Loss: 0.019 -- Acc: 0.952\n",
            "  Trues: ['-53y', '92d', '-17y', '10m', '55d', '42y', '31m']\n",
            "  Preds: ['-53y', '92d', '-17y', 'zehnm', '55d', '42y', '31m']\n",
            "[Epoch: 13/50] | Train Loss: 0.054 -- Valid Loss: 0.017 -- Acc: 0.952\n",
            "  Trues: ['42y', '31m', '55m', '4d', '3m', '59d', '-31m']\n",
            "  Preds: ['42y', '31m', '55m', '4d', '3m', '59d', '-31m']\n",
            "[Epoch: 14/50] | Train Loss: 0.047 -- Valid Loss: 0.015 -- Acc: 0.962\n",
            "  Trues: ['92d', '-17y', '10m', '55d', '42y', '31m', '55m']\n",
            "  Preds: ['92d', '-17y', 'zehnm', '55d', '42y', '31m', '55m']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-44a07b5444d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SZ\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mWINDOW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to show random trues and preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mloss_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[Epoch: {step}/{N_EPOCHS}] |'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-73f3c6588680>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0msource_token_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0msource_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mtarget_token_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-fec454bff144>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, att_mask, labels)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matt_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mlm_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             )\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_outputs, decoder_input_ids, decoder_attention_mask, decoder_past_key_value_states, use_cache, lm_labels, inputs_embeds, decoder_inputs_embeds, head_mask)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             encoder_outputs = self.encoder(\n\u001b[0;32m-> 1063\u001b[0;31m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m             )\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, past_key_value_states, use_cache)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0mpast_key_value_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             )\n\u001b[1;32m    739\u001b[0m             \u001b[0;31m# layer_outputs is a tuple with:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, head_mask, past_key_value_state, use_cache)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mpast_key_value_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         )\n\u001b[1;32m    515\u001b[0m         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_key_value_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, head_mask, past_key_value_state, use_cache)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mpast_key_value_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         )\n\u001b[1;32m    426\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, mask, kv, position_bias, past_key_value_state, head_mask, query_length, use_cache)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mpresent_key_value_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bnqd,bnkd->bnqk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, qlen, klen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mposition_bias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# the old interface of passing the operands as one list argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0moperands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWAhh3gOgg2c",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfRFVIBSgiau",
        "colab_type": "code",
        "outputId": "ac5243d1-1ec6-4088-ca18-ffd06cd49460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# ---------------------------------------------------------------------------------\n",
        "start.record()\n",
        "\n",
        "samp = random.randint(0, BATCH_SZ-WINDOW) # to show random trues and preds\n",
        "loss, acc, trues, preds = evaluate_fn(model, device, dataloaders['test'])\n",
        "print(f'Loss: {loss:.3f} -- Acc: {acc:.3f}')\n",
        "print(f' Trues: {trues[samp:samp+WINDOW]}\\n  Preds: {preds[samp:samp+WINDOW]}')\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()    \n",
        "# ---------------------------------------------------------------------------------\n",
        "\n",
        "print(f'Test time: {start.elapsed_time(end)/1000/60 :.3f} min.')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.008 -- Acc: 0.988\n",
            " Trues: ['-2m', '2m', '3m', '3y', '-3m', '-3d', '-4m']\n",
            "  Preds: ['-2m', '2m', '3m', '3y', '-3m', '-3d', '-4m']\n",
            "Test time: 0.038 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzVjYAkNGVxJ",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating types for a same date\n",
        "\n",
        "Given a sample date, this section evaluates wich is the accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DixMx530hPg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_for_a_same_date(date,model=model,tokenizer=TOK,verbose=True):\n",
        "  '''\n",
        "    Given a specific date, returns the accuracy in all evalueated types.\n",
        "    Also prints results per sample.\n",
        "  '''\n",
        "\n",
        "  results = []\n",
        "  \n",
        "  examples = datas.generate_demo(date=date)\n",
        "\n",
        "  for x,target in zip(examples['Generated Text'],examples['Origin Sample']):\n",
        "\n",
        "    prediction = model.generate_example(x,TOK)[0]\n",
        "\n",
        "    results.append(prediction == target)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'Entrada: {x} -- Target: {target} --- Previsto: {prediction} --- {prediction == target}')\n",
        "\n",
        "  if verbose:\n",
        "    print(f'Total accuracy: {np.mean(results)}')\n",
        "\n",
        "  return np.mean(results)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmH30k9iBKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  A date in the century with more dates occuring\n",
        "'''\n",
        "evaluate_for_a_same_date('11/07/1988')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZr2RlmzcjLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  A date in a century with less dates occurring, but that is inside the\n",
        "  generated dataset\n",
        "'''\n",
        "evaluate_for_a_same_date('20/12/2015')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqonQb-kcjUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  Evaluating for a date in a century out of the training range gives the worst\n",
        "  acc possible. (0)\n",
        "'''\n",
        "evaluate_for_a_same_date('25/12/2141')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMnT5Sm-IPMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  An earlier date than the beggining of the generated dataset\n",
        "'''\n",
        "evaluate_for_a_same_date('27/05/1920')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0jwndLKmxpX",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy in dataset dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpd5akZyAXyz",
        "colab_type": "text"
      },
      "source": [
        "## Inside dataset\n",
        "\n",
        "Dates into the interval that was used to built the synthetic dataset used for test and eval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfHmTxgDm19i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accs = []\n",
        "dates = []\n",
        "\n",
        "sampled_test = random.sample(list(df['Target'].values),50)\n",
        "\n",
        "print('acc test set: ',sampled_test)\n",
        "\n",
        "for date_sample in sampled_test:\n",
        "  accs.append(evaluate_for_a_same_date(date_sample,verbose=False))\n",
        "  dates.append(date_sample)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxzyKeRQoBTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(dates,accs)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.ylim([0.8, 1.01])\n",
        "plt.ylabel('Average accuracy on 45 formats')\n",
        "plt.xlabel('Canonical target')\n",
        "plt.title('Average accuracy on dates inside synthetic training dataset')\n",
        "print('Average of average accuracies: ',np.mean(accs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePEpzTU5A0Rx",
        "colab_type": "text"
      },
      "source": [
        "## Below dataset\n",
        "\n",
        "Dates lower than the synthetic dataset used for test and eval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8gnAWTcd5DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accs = []\n",
        "dates = []\n",
        "\n",
        "new_dataset = DateTextGenerator('01/01/1900','31/12/1920')\n",
        "\n",
        "new_df = new_dataset.generate_date_dataset()\n",
        "sampled_test = random.sample(list(new_df['Target'].values),20)\n",
        "\n",
        "print('acc test set: ',sampled_test)\n",
        "\n",
        "for date_sample in sampled_test:\n",
        "  accs.append(evaluate_for_a_same_date(date_sample,verbose=False))\n",
        "  dates.append(date_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4DFUtHoUA2c4",
        "colab": {}
      },
      "source": [
        "plt.plot(dates,accs)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.ylabel('Average accuracy on 45 formats')\n",
        "plt.xlabel('Canonical target')\n",
        "plt.title('Average accuracy on dates below synthetic training dataset')\n",
        "print('Average of average accuracies: ',np.mean(accs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H0BR5SlBCCEr"
      },
      "source": [
        "## Above dataset\n",
        "\n",
        "Dates greater than the synthetic dataset used for test and eval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86KqAIP8ef_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accs = []\n",
        "dates = []\n",
        "\n",
        "new_dataset = DateTextGenerator('01/01/2121','31/12/2140')\n",
        "\n",
        "\n",
        "new_df = new_dataset.generate_date_dataset()\n",
        "sampled_test = random.sample(list(new_df['Target'].values),20)\n",
        "\n",
        "print('acc test set: ',sampled_test)\n",
        "\n",
        "for date_sample in sampled_test:\n",
        "  accs.append(evaluate_for_a_same_date(date_sample,verbose=False))\n",
        "  dates.append(date_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J2SP31YSCCFG",
        "colab": {}
      },
      "source": [
        "plt.plot(dates,accs)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.ylabel('Average accuracy on 45 formats')\n",
        "plt.xlabel('Canonical target')\n",
        "plt.title('Average accuracy on dates above synthetic training dataset')\n",
        "print('Average of average accuracies: ',np.mean(accs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bvkIIgMNASY",
        "colab_type": "text"
      },
      "source": [
        "# The End"
      ]
    }
  ]
}